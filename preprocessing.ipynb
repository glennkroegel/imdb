{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from transformers import *\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "# import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-use-torchtext-for-neural-machine-translation-plus-hack-to-make-it-5x-faster-77f3884d95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'utils.py',\n",
       " 'aclImdb_v1.tar.gz',\n",
       " 'aclImdb',\n",
       " 'preprocessing.ipynb',\n",
       " 'model.py',\n",
       " 'classifier.py',\n",
       " 'join_datasets.ipynb',\n",
       " 'base.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data.csv')\n",
    "data['L'] = data['text'].str.count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('L < 180')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, cv = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=None)\n",
    "cv.to_csv('cv.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((463, 3), (52, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
    "          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
    "          (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n",
    "          (CTRLModel,       CTRLTokenizer,       'ctrl'),\n",
    "          (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
    "          (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
    "          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
    "          (DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased'),\n",
    "          (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, weights = MODELS[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will', 'is', 'a', 'massive', 'cu', '##nt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('Will is a massive cunt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en = spacy.load('en_core_web_sm')\n",
    "# def tokenize(sentence):\n",
    "#     return [tok.text for tok in en.tokenizer(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, \n",
    "             tokenize=tokenize, \n",
    "             use_vocab=True,\n",
    "             init_token = tokenizer.cls_token,\n",
    "             pad_token=tokenizer.pad_token, \n",
    "             unk_token=tokenizer.unk_token,\n",
    "             pad_first=False, \n",
    "             batch_first=True)\n",
    "LABEL = Field(use_vocab=False, sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafields = [('text', TEXT), ('label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, cv = TabularDataset.splits(path='.',\n",
    "                                train='train.csv', \n",
    "                                validation='cv.csv', \n",
    "                                format='csv', \n",
    "                                skip_header=True, \n",
    "                                fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = dict(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = list(stoi.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.stoi = stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.itos = itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    " (trn, cv), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_sizes=(6, 6),\n",
    " device=torch.device('cpu'), # if you want to use the GPU, specify the GPU number here\n",
    " sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=True,\n",
    " repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2009,  1005,  1055,  2182,  1012,  2633,  1037,  3185,  3310,\n",
       "          2041,  2008,  1045,  2064,  9826,  2360,  2003,  4788,  2084,  6554,\n",
       "          1996,  5830,  3124,  1024,  2740,  7742,  1012,  2664,  1045,  1005,\n",
       "          1049,  5627,  2000,  6655,  1996,  1996,  2126,  2319,  1005,  1055,\n",
       "          3428,  1006, 26316,  1007,  2097,  2191,  2062,  2769,  2084,  1045,\n",
       "          2412,  2191,  1999,  2026,  2878,  2166,  2006,  2054,  2003,  2469,\n",
       "          2000,  2022,  2028,  1997,  1996,  2327,  2274,  5409,  3152,  1997,\n",
       "          2035,  2051,  1010,  2648,  1997,  2026,  3587,  3694,  2648,  1996,\n",
       "          2465,  2128,  1011, 26465,  1997, 12390,  1998, 13707,  1012,  1045,\n",
       "          2812,  2428,  2339,  2052,  3087,  2412,  2412,  2156,  2023,  3185,\n",
       "          4983,  2027,  2020,  3825,  2000,  1012,  1996,  4038,  2003,  5410,\n",
       "          1998,  2035,  2130, 19512,  6057, 13198,  2013,  1996, 13109,  5714,\n",
       "          6508,  5436,  2020,  7543,  3936,  1999, 12698,  1012,  2345,  2773,\n",
       "          2003,  2023,  3185,  2001,  1037,  6659,  2292,  7698,  2005,  2033,\n",
       "          1012,  1998,  1996, 12698,  2246,  2061, 10015,  1012,  1012,  1012],\n",
       "        [  101,  1037,  2986,  3235,  2080, 26256,  1010,  2023,  2003,  1037,\n",
       "         24462,  1998, 22249, 27699,  7174,  2007,  2986,  4616,  2013,  2204,\n",
       "          2559,  3459,  1998, 16552,  1996,  2048,  5260,  1010,  2577, 15481,\n",
       "          1998, 12918,  2358,  6657, 25190,  1012,  1026,  7987,  1013,  1028,\n",
       "          1026,  7987,  1013,  1028,  2005,  2033,  1996, 10147,  2290,  1011,\n",
       "          2387, 11989,  1997,  1037,  5436,  2003,  2061,  9530,  6767,  7630,\n",
       "          3064,  1998, 16801,  2017,  2074,  4133,  2067,  1998,  5959,  2738,\n",
       "          2084,  3046,  2000,  3424,  6895, 17585,  1012,  2074,  2043,  2035,\n",
       "          3849, 10395,  2057,  2024,  2153,  2579,  2006,  1037,  2582,  2186,\n",
       "          1997, 21438,  1010, 22249, 21438,  1010,  2009,  2038,  2000,  2022,\n",
       "          2056,  1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,\n",
       "          7916,  2007,  7564,  1997,  2175,  2854,  8563,  2023,  1037,  2092,\n",
       "         13823,  3185,  2007,  2414,  1010,  7571,  1998,  3306,  5780,  5269,\n",
       "          1012,  1037,  3565,  9599,  2275,  2588, 27198,  5749, 19735,  2477,\n",
       "          2039,  1998,  2172,  4569,  2001,  2018,  2011,  2035,  1012,     0],\n",
       "        [  101,  2013,  2673,  1045,  1005,  1040,  3191,  2055,  1996,  3185,\n",
       "          1010,  1045,  2001,  7568,  2000,  2490,  1037,  2143,  2007,  1037,\n",
       "          3017,  4323,  1012,  2673,  2055,  1996,  3185,  2001,  2200,  4895,\n",
       "         21572,  7959, 28231,  3973,  2589,  1012,  2926,  1996,  3015,   999,\n",
       "          2302,  2204,  3015,  1037,  3185,  2987,  1005,  1056,  2031,  1037,\n",
       "          3382,  1012,  1996,  3213,  1013,  2472,  2056,  1999,  2019,  4357,\n",
       "          2008,  2002,  2134,  1005,  1056,  2215,  2000,  2507,  2185,  2129,\n",
       "          1996,  2516, 14623,  2000,  1996,  2466,  1012,  2903,  2033,  1010,\n",
       "          2009,  2001,  2053,  2502,  4474,  1012,  1045,  2921,  3403,  2005,\n",
       "          1996,  9454,  1013,  2402,  4639,  2067,  1011,  2466,  2000,  4895,\n",
       "         10371,  1010,  2021,  2009,  2196,  2106,  1012,  2004,  2619,  2040,\n",
       "          2038,  2908,  2083,  1037,  8179,  1010,  1045,  2001,  2200,  9364,\n",
       "          1012,  2023,  3185,  2052,  2031,  2042,  2053,  7216,  2000,  2033,\n",
       "          2043,  1045,  2034,  2253,  2083,  1996,  6832, 17930,  2008,  8179,\n",
       "          2064,  3288,  2000,  2115,  2166,  2004,  1037,  3017,   999,     0],\n",
       "        [  101,  1996,  2143,  2003, 27564, 22249,  2007,  1037,  2307,  3459,\n",
       "          1010,  1998,  6581,  3257,  2011,  2508,  6574,  2015,  1012,  1996,\n",
       "          3185,  2003, 14036,  2007,  1037,  2200, 23916,  2836,  2013, 11496,\n",
       "         21760,  3286,  1998,  3071,  2003,  6669,  3459,  1012,  2508,  6574,\n",
       "          2015,  2038,  1037,  2204,  3239,  2005,  9179,  1998, 23303,  2066,\n",
       "          1037,  7589,  4209,  3599,  2043,  2000, 27987,  2039,  1996,  2895,\n",
       "          1010,  2991,  1998,  2059,  4125,  2000,  1037, 14463,  1012,  2002,\n",
       "          2515,  2023,  2007,  2019,  5783,  1997, 17211,  1010,  7564,  1997,\n",
       "         21438,  1010, 16959,  2015,  1998,  2668,  1012,  2023,  2003,  1037,\n",
       "          2709,  1997,  1996,  2214,  4393,  3185,  1010,  2007, 15665,  1997,\n",
       "         13638,  1010,  2668,  1998, 11652,  1012,  1996,  3185,  2573,  2012,\n",
       "          1037,  2307,  3177,  1998,  1996,  3494,  2202,  2017,  2006,  1037,\n",
       "         27547,  6172,  1010,  2021,  2054,  3084,  2009,  2147,  2003,  2008,\n",
       "          1996,  2143,  2987,  1005,  1056,  2202,  2993,  2205,  5667,  2007,\n",
       "          7564,  1997,  4416,  1999,  5048,  2895,  1012,  2307,   999,     0],\n",
       "        [  101,  1045,  2387,  1996,  9117,  2000,  2023,  2143,  1998,  2009,\n",
       "          2246,  2307,  1010,  2061,  1045,  2253,  2041,  1998,  4149,  2009,\n",
       "          1012,  2054,  1037,  6707,  1010,  1996,  3772,  2003,  1037, 25850,\n",
       "         13510,  1010,  1996,  2569,  3896,  1006,  2065,  2017,  2071,  2655,\n",
       "          2068,  2008,  1007,  1010,  2298,  2066,  2242,  2008,  2876,  1005,\n",
       "          1056,  2022,  2041,  1997,  2173,  2012,  1037,  2082,  2377,  1012,\n",
       "          2070,  1997,  1996,  3494,  2024,  2061,  5236,  1999,  2023,  2143,\n",
       "          2017,  2097, 13675, 23496,  1996,  3371,  2027,  2024,  2006,  1996,\n",
       "          3898,  1010,  2029,  6854,  2003,  2035,  2000,  2411,  1012,  2004,\n",
       "          2005,  1037,  2466,  1010,  5293,  2009,  1012,  2023,  2003,  1037,\n",
       "          5432,  1010,  2123,  1005,  1056,  5949,  2151,  2769,  2012,  2035,\n",
       "          2006,  2023,  2143,  2009,  2038,  2000,  2022,  2028,  1997,  1996,\n",
       "          5409,  2477,  1045,  2031,  2412,  2464,  1012,  2065,  1010,  2005,\n",
       "          2070,  3114,  1010,  2017,  2066,  2023,  2143,  3422, 18792,  1016,\n",
       "          1010,  2017,  2097,  2763,  5959,  2008,  2004,  2092,  1012,     0],\n",
       "        [  101,  5760, 25026, 23447, 11067,  3084,  2023,  2028,  1997,  1996,\n",
       "          4602,  1997,  5691,  1012, 23447,  2003,  4567,  2046,  1037,  4028,\n",
       "          9714,  2069,  2000,  2022,  2275,  2039,  2004,  1996,  2991,  3124,\n",
       "          1010,  2029,  2003,  2054,  2002,  5218,  2000,  2007,  1996, 22473,\n",
       "          7615,  1000,  2502, 24369,  2008,  1045,  2572,  1012,  1000,  5436,\n",
       "          2003,  2061,  3375,  2008,  1045,  2145,  2123,  1005,  1056,  2113,\n",
       "          3251,  1996,  6778,  2354,  2008,  2010,  2166,  2001,  2055,  2000,\n",
       "          2022,  2439,  1012,  1996, 18297,  3496,  1999,  1996, 11485,  2534,\n",
       "          1997, 13536,  2003,  2028,  1997,  1996,  2087,  6429,  2412,  6361,\n",
       "          1012,  2008,  3496,  2894,  2003,  4276,  1996,  3976,  1997,  9634,\n",
       "          1012,  2023,  2003,  1996,  2069,  2051,  2008, 11620, 10974,  5172,\n",
       "          2412,  2209,  1037,  3375,  2664, 19337,  2666, 12423,  2839,  1012,\n",
       "          2053,  2028,  2021, 23447,  2052,  2031,  2018,  1996,  9113,  2000,\n",
       "          3013,  2014,  2606,  1998, 18554,  2009,  8782,  2100,  8855,  1012,\n",
       "          2053,  2028,  2323,  3335,  2023,  3861,  1012,     0,     0,     0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] i saw the trailer to this film and it looked great, so i went out and bought it. what a mistake, the acting is a shambles, the special effects ( if you could call them that ), look like something that wouldn't be out of place at a school play. some of the characters are so stupid in this film you will cringe the minute they are on the screen, which unfortunately is all to often. as for a story, forget it. this is a warning, don't waste any money at all on this film it has to be one of the worst things i have ever seen. if, for some reason, you like this film watch troll 2, you will probably enjoy that as well. [PAD]\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch.text[4].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_iter:\n",
    "    x = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_class.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(x.text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    " (trn, cv), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_sizes=(6, 6),\n",
    " device=torch.device('cuda'), # if you want to use the GPU, specify the GPU number here\n",
    " sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False,\n",
    " repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_iter, 'train_iter.pt')\n",
    "torch.save(val_iter, 'cv_iter.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
